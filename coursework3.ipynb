{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import faiss\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,  LlamaForCausalLM\n",
    "from transformers import GenerationConfig, LlamaTokenizer, LlamaForCausalLM\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from evaluate import logging, load\n",
    "torch.set_num_threads(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset disfl_qa (/home/kate/.cache/huggingface/datasets/disfl_qa/default/1.1.0/ff7a7331d2d842de6c0951a1525008cdb4116a5f8d82f990e158f15984a9d6d8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215d1b183b8144a9a0d584fe52e17186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['squad_v2_id', 'original question', 'disfluent question', 'title', 'context', 'answers'],\n",
       "        num_rows: 7182\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['squad_v2_id', 'original question', 'disfluent question', 'title', 'context', 'answers'],\n",
       "        num_rows: 3643\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['squad_v2_id', 'original question', 'disfluent question', 'title', 'context', 'answers'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_qa = load_dataset('disfl_qa')\n",
    "distil_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_qa (/home/kate/.cache/huggingface/datasets/tweet_qa/default/1.0.0/7d588f7f477946b10f60c035ca55175737315ac446102b015218af38d2638777)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72485072934a4b74b0e9907458716ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
       "        num_rows: 10692\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
       "        num_rows: 1979\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Question', 'Answer', 'Tweet', 'qid'],\n",
       "        num_rows: 1086\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data = load_dataset('tweet_qa')\n",
    "tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/home/kate/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3709eaa508a74ae28bb5b4fe3a62bd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad = load_dataset(\"squad\")\n",
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad_v2 (/home/kate/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd32e2bacea49eebfc5912d5cbd55f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 130319\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad2 = load_dataset(\"squad_v2\")\n",
    "squad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'Answer', 'context', 'qid'],\n",
       "        num_rows: 10692\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'Answer', 'context', 'qid'],\n",
       "        num_rows: 1979\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'Answer', 'context', 'qid'],\n",
       "        num_rows: 1086\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data = tweets_data.rename_column('Tweet', 'context')\n",
    "tweets_data = tweets_data.rename_column('Question', 'question')\n",
    "distil_qa = distil_qa.rename_column('disfluent question', 'question')\n",
    "tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers', 'squad_v2_id', 'original question', 'Answer', 'qid'],\n",
       "    num_rows: 255373\n",
       "})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_store = concatenate_datasets([squad['train'], squad2['train'], squad2['validation'], \n",
    "                                        distil_qa['train'], distil_qa['test'], distil_qa['validation'],\n",
    "                                        tweets_data['train'], tweets_data['test'], tweets_data['validation']]\n",
    "                                            )\n",
    "dataset_to_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yahoo_answers_qa (/home/kate/.cache/huggingface/datasets/yahoo_answers_qa/yahoo_answers_qa/1.0.0/62f63c2dc317317049c5a213c97370fe2989ead076488347df250a4b35da10d7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'answer', 'nbestanswers', 'main_category'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yahoo = load_dataset('yahoo_answers_qa', split='train[:5000]')\n",
    "yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/kate/.cache/huggingface/datasets/yahoo_answers_qa/yahoo_answers_qa/1.0.0/62f63c2dc317317049c5a213c97370fe2989ead076488347df250a4b35da10d7/cache-4f3fc4cfd03544ac.arrow\n",
      "Loading cached shuffled indices for dataset at /home/kate/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-6287bafd17ab2657.arrow\n"
     ]
    }
   ],
   "source": [
    "shuffled_qa = yahoo.shuffle(seed=1)[:500]\n",
    "shuffled_squad = squad['validation'].shuffle(seed=1)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn_store():\n",
    "    def __init__(self, data) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.max_embedding_len = self.tokenizer.max_model_input_sizes['distilbert-base-uncased']\n",
    "        self.data = data\n",
    "        self.keys = self.create_keys()\n",
    "        self.values = self.create_values()\n",
    "        \n",
    "    def create_keys(self):\n",
    "        questions = [q.strip() for q in self.data[\"question\"]]\n",
    "        keys = self.tokenizer(questions,\n",
    "                                max_length=self.max_embedding_len,\n",
    "                                truncation=\"only_second\",\n",
    "                                padding=\"max_length\",\n",
    "                                return_tensors='pt')\n",
    "        return keys['input_ids']\n",
    "    \n",
    "    def create_values(self):\n",
    "        context = [x for x in self.data['context']]\n",
    "        values = self.tokenizer(context,\n",
    "                            max_length=self.max_embedding_len,\n",
    "                            truncation=True,\n",
    "                            padding=\"max_length\",\n",
    "                            return_tensors='pt')\n",
    "        return values['input_ids']\n",
    "    \n",
    "    def set_index(self):\n",
    "        self.index = faiss.IndexFlatL2(self.max_embedding_len)\n",
    "        keys_formatted = self.keys.detach().cpu().float().numpy()\n",
    "        # faiss.normalize_L2(keys_formatted)\n",
    "        self.index.add(keys_formatted) \n",
    "    \n",
    "    def save_storage(self):\n",
    "        faiss.write_index(self.index, \"knn_index\")\n",
    "        torch.save(self.values, \"contexts.t\")\n",
    "        \n",
    "        \n",
    "def build_storage(data):\n",
    "    storage = knn_store(data)\n",
    "    storage.set_index()\n",
    "    storage.save_storage()\n",
    "    \n",
    "build_storage(dataset_to_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn():\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.max_embedding_len = self.tokenizer.max_model_input_sizes['distilbert-base-uncased']\n",
    "        self.index = self.init_index()\n",
    "        self.context = self.init_context()\n",
    "    \n",
    "    def init_index(self):\n",
    "        return faiss.read_index(\"knn_index\")\n",
    "        \n",
    "    def init_context(self):\n",
    "        return torch.load(\"contexts.t\")\n",
    "    \n",
    "    def search_knn(self, encoded_input, k = 1):\n",
    "        encoded_input = encoded_input.detach().cpu().float().numpy()\n",
    "        # faiss.normalize_L2(encoded_input)\n",
    "        if len(encoded_input.shape) == 1:\n",
    "            encoded_input = encoded_input[0:1]\n",
    "            \n",
    "        knn_distances, knn_indexes = self.index.search(encoded_input, k)\n",
    "        return knn_distances, knn_indexes\n",
    "    \n",
    "    def encode_question(self, question):\n",
    "        encoded_question = self.tokenizer(question, \n",
    "                                          max_length=self.max_embedding_len,\n",
    "                                          truncation=\"only_second\",\n",
    "                                          padding=\"max_length\",\n",
    "                                          return_tensors='pt')\n",
    "        return encoded_question['input_ids']\n",
    "    \n",
    "    def make_prompt(self, question, k = 1):\n",
    "        encoded_question = self.encode_question(question)\n",
    "        knn_distances, knn_indexes = self.search_knn(encoded_question, k)\n",
    "        text_to_add = [self.tokenizer.decode(e, skip_special_tokens=True) for e in self.context[knn_indexes.tolist()]]\n",
    "        return \" \".join(text_to_add)\n",
    "    \n",
    "knn = knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7b74300db34d86b834ee5fc1f84e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "checkpoint = \"chainyo/alpaca-lora-7b\"\n",
    "# checkpoint = \"huggyllama/llama-7b\"\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained( checkpoint, low_cpu_mem_usage=True)\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(instruction, input=None):  \n",
    "    if input:\n",
    "        return f\"\"\"Below is an instruction that describes an answer, paired with an input that provides context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "### Input:\n",
    "{input}\n",
    "### Response:\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes an answer. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "### Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_score = load('meteor')\n",
    "    \n",
    "def compute_meteor(predictions, references):\n",
    "    \n",
    "    if type(predictions) == str:\n",
    "        predictions = [predictions]\n",
    "    if type(references) == str:\n",
    "        references = [references]\n",
    "        \n",
    "    return meteor_score.compute(predictions=predictions, references=references)['meteor']\n",
    "\n",
    "def compute_f1(pred, real):\n",
    "        \n",
    "    if len(pred) == 0 or len(real) == 0:\n",
    "        return int(pred == real)\n",
    "    \n",
    "    common_tokens = set(pred)&set(real)\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred)\n",
    "    rec = len(common_tokens) / len(real)\n",
    "    \n",
    "    return prec, rec,  2 * prec * rec / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    instruction,\n",
    "    right_answer,\n",
    "    input=None,\n",
    "    # temperature=1.0,\n",
    "    temperature=0.1,\n",
    "    # top_p=0.75,\n",
    "    top_p = 0.95,\n",
    "    top_k=40,\n",
    "    num_beams=4,\n",
    "    max_new_tokens=128,\n",
    "    **kwargs,\n",
    "):\n",
    "\n",
    "    prompt = generate_prompt(instruction, input)\n",
    "    inputs = tokenizer(prompt, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    right_answer_tokenized = tokenizer(right_answer, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    right_answer_tokenized = right_answer_tokenized['input_ids'].to(device)\n",
    "\n",
    "    generation_config = GenerationConfig(\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        num_beams=num_beams,\n",
    "        **kwargs,\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        \n",
    "    s = generation_output.sequences[0]\n",
    "    \n",
    "    precision, recall, f1 = compute_f1(s.tolist(), *right_answer_tokenized.tolist())\n",
    "\n",
    "    output = tokenizer.decode(s, skip_special_tokens=True)\n",
    "    answer = output.split(\"### Response:\")[1].strip()\n",
    "    meteor = compute_meteor(answer, right_answer)\n",
    "\n",
    "    return precision, recall, f1, meteor, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(\n",
    "    predictions, batch_size: int = 16, max_length=128):\n",
    "    device='cpu'\n",
    "    \n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        \"chainyo/alpaca-lora-7b\",\n",
    "        low_cpu_mem_usage=True\n",
    "        )\n",
    "    \n",
    "    tokenizer = LlamaTokenizer.from_pretrained(\"chainyo/alpaca-lora-7b\")\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        predictions,\n",
    "        add_special_tokens=False,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\",\n",
    "        return_attention_mask=True,\n",
    "    ).to(device)\n",
    "\n",
    "    encoded_texts = encodings[\"input_ids\"]\n",
    "    attn_masks = encodings[\"attention_mask\"]\n",
    "\n",
    "    ppls = []\n",
    "    loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "    \n",
    "    for start_index in logging.tqdm(range(0, len(encoded_texts), batch_size)):\n",
    "        end_index = min(start_index + batch_size, len(encoded_texts))\n",
    "        encoded_batch = encoded_texts[start_index:end_index]\n",
    "        attn_mask = attn_masks[start_index:end_index]\n",
    "\n",
    "        labels = encoded_batch\n",
    "        with torch.no_grad():\n",
    "            output = model(encoded_batch, attention_mask=attn_mask)\n",
    "            out_logits = output.logits\n",
    "\n",
    "        shift_logits = out_logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "        shift_attention_mask_batch = attn_mask[..., 1:].contiguous()\n",
    "\n",
    "        perplexity_batch = torch.exp(\n",
    "            (loss_fct(shift_logits.transpose(1, 2), shift_labels) * shift_attention_mask_batch).sum(1)\n",
    "            / shift_attention_mask_batch.sum(1)\n",
    "        )\n",
    "\n",
    "        ppls += perplexity_batch.tolist()\n",
    "\n",
    "    return {\"perplexities\": ppls, \"mean_perplexity\": np.mean(ppls)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "q = What is expected with the continuous input of sediment into the Dornbirner Ach?\n",
      "pred = It is expected that the continuous input of sediment into the lake will silt up the lake. This has already happened to the former lake Tuggenersee.\n",
      "right = {'text': ['silt', 'silt up the lake', 'the continuous input of sediment into the lake will silt up the lake', 'silt up the lake'], 'answer_start': [502, 502, 450, 502]}\n",
      "1\n",
      "q = Which of the three heavily populated areas has the least number of inhabitants?\n",
      "pred = The area with the least number of inhabitants is the El Centro area.\n",
      "right = {'text': ['San Diego', 'the San Diego area', 'San Diego'], 'answer_start': [793, 789, 793]}\n",
      "2\n",
      "q = How many of the following three fourth quarter drives after the field goal makng the score 16-10 ended in punts?\n",
      "pred = Two of the three fourth quarter drives ended in punts.\n",
      "right = {'text': ['three', 'three', 'The next three drives'], 'answer_start': [444, 444, 435]}\n",
      "3\n",
      "q = What would the latter Apollo missions carry to the moon to increase exploration?\n",
      "pred = The latter Apollo missions would carry to the moon to increase exploration. They would carry scientific instruments, cameras, and other equipment to study the moon's surface.\n",
      "right = {'text': ['Lunar Roving Vehicle (LRV)', 'payload capacity', 'Lunar Roving Vehicle', 'lunar orbital sensors and cameras', 'Lunar Roving Vehicle'], 'answer_start': [577, 260, 577, 406, 577]}\n",
      "4\n",
      "q = What are cestida called?\n",
      "pred = The cestida are called belt animals. They are ribbon-shaped planktonic animals, with the mouth and aboral organ aligned in the middle of opposite edges of the ribbon. There is a pair of comb-rows along each aboral edge, and tentilla emerging from a groove all along the oral edge, which stream back across most of the wing-like body surface. Cestids can swim by undulating their bodies as well as by the beating of their comb-rows. There are two known species, with worldwide distribution in warm, and warm-temperate\n",
      "right = {'text': ['belt animals', 'belt animals', '\"belt animals\"'], 'answer_start': [14, 14, 13]}\n",
      "5\n",
      "q = What team did the Denver Broncos play in  Super Bowl XXXIII?\n",
      "pred = The Denver Broncos played the Atlanta Falcons in Super Bowl XXXIII.\n",
      "right = {'text': ['Atlanta Falcons', 'the Atlanta Falcons', 'Falcons'], 'answer_start': [376, 372, 384]}\n",
      "6\n",
      "q = Of what material were the death rays pellets made?\n",
      "pred = The death rays pellets were made of metal.\n",
      "right = {'text': ['tungsten', 'tungsten', 'tungsten'], 'answer_start': [288, 288, 288]}\n",
      "7\n",
      "q = What was Elway's final game as the Denver quarterback?\n",
      "pred = According to Pew Research, 7% of the population identifies as Christian; 4% as Muslim; 1% follows traditional animistic beliefs; and 2% follow other religions, including Mahayana Buddhism, Hinduism, and East Asian religions. However, according to a US State Department's 2010 International Religious Freedom Report, official statistics are alleged to underestimate the non-Buddhist population. Independent researchers put the Muslim population at 6 to 10% of the population [citation needed]. Jehovah'\n",
      "right = {'text': ['Super Bowl XXXIII', 'Super Bowl XXXIII', 'Super Bowl XXXIII'], 'answer_start': [302, 302, 302]}\n",
      "8\n",
      "q = In which case was it held that the provisions of the treaties are directly effective if they are clear, unconditional, and don't require further action by EU or national authorities?\n",
      "pred = The provisions of the treaties are directly effective if they are clear, unconditional, and do not require further action by EU or national authorities.\n",
      "right = {'text': ['Van Gend en Loos v Nederlandse Administratie der Belastingen', 'Van Gend en Loos v Nederlandse Administratie der Belastingen', 'Van Gend en Loos v Nederlandse Administratie der Belastingen'], 'answer_start': [165, 165, 165]}\n",
      "9\n",
      "q = When did Tesla make the induction motor?\n",
      "pred = Tesla made the induction motor in 2014.\n",
      "right = {'text': ['1887', '1887', '1887'], 'answer_start': [56, 56, 56]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(i, f'q = {shuffled_squad[\"question\"][i]}', f'pred = {squad_predictions[i]}', f'right = {shuffled_squad[\"answers\"][i]}', sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A small group of politicians believed strongly that the fact that Saddam Hussien remained in power after the first Gulf War was a signal of weakness to the rest of the world, one that invited attacks and terrorism. Shortly after taking power with George Bush in 2000 and after the attack on 9/11, they were able to use the terrorist attacks to justify war with Iraq on this basis and exaggerated threats of the development of weapons of mass destruction. The military strength of the U.S. and the brutality of Saddam's regime led them to imagine that the military and political victory would be relatively easy.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['answer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_precisions = []\n",
    "squad_recalls = []\n",
    "squad_f1s = []\n",
    "squad_predictions= []\n",
    "squad_meteors = []\n",
    "for i in tqdm.tqdm(range(0, 300)):\n",
    "    context = knn.make_prompt(shuffled_squad['question'][i], k=1)\n",
    "    precision, recall, f1, meteor, pr = evaluate(shuffled_squad['question'][i], shuffled_squad['answer'][i]['text'][0], context)\n",
    "    squad_precisions.append(precision)\n",
    "    squad_recalls.append(recall)\n",
    "    squad_f1s.append(f1)\n",
    "    squad_predictions.append(pr)\n",
    "    squad_meteors.append(meteor)\n",
    "    \n",
    "squad_perplexity = compute_perplexity(squad_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.338759223620098"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "open_file = open('predictions_squad_shuffle_300_knn.pkl', \"wb\")\n",
    "pickle.dump(squad_predictions, open_file)\n",
    "open_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
